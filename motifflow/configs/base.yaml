defaults:
  - _self_
  - datasets
  - structure
  - latent

data:
  task: inpainting # inpainting, prediction(?)
  dataset: PDB # PDB, SCOPe, AFDB / multimer, mmcif
  loader:
    num_workers: 8
    prefetch_factor: 10
  sampler:
    # Setting for 48GB GPUs
    max_batch_size: 1  # 80 # if using crop_non_chain_residues, max_batch_size should be 1 + in mmcif dataset...
    max_num_res_squared: 400000 # 400000

experiment:
  objective: LDM # VAE, joint, LDM
  debug: false
  seed: 123
  num_devices: 2
  load_ckpt: ckpt/fm_mms_vae/LDM_PDB_pairformer/joint_pdb_v0.0.2_pairformer_4_0.01_ze_8_99epoch.ckpt # ckpt/fm_mms_vae/VAE_pdb_MPNN_4_0.01_logits/epoch=19_start.ckpt # inpainting_multimer_v0.1.2_ft/last_244.ckpt  # null
  continous_training: False
  use_ckpt_model_cfg: False
  start_training_VAE_epoch: 10
  
  training:
    valid_designability: False
    # VAE training
    beta_max: 0.01 #0.01
    total_annealing_epochs: 30
    # joint training
    warmup_epochs: 20
    vae_loss_weight: 8
    mask_plddt: True
    bb_atom_scale: 0.1
    trans_scale: 0.1
    translation_loss_weight: 2.0
    t_normalize_clip: 0.9
    rotation_loss_weights: 1.0
    aux_loss_weight: 1.0
    aux_loss_use_bb_loss: True
    aux_loss_use_pair_loss: True
    aux_loss_t_pass: 0.5
    motif_condition_loss_weight : 1
    # LDM training
    use_structure_loss: false
    structure_loss_weight: 0.0
    contact_map_loss_weight: 0.1

  wandb:
    project: fm_mms_vae
    name: ${experiment.objective}_${data.dataset}_pairformer
  optimizer:
    lr: 0.0001
  latent_diffusion_optimizer:
    lr: 0.0001
    betas: [0.9, 0.999]
    weight_decay: 0
  trainer:
    overfit_batches: 0
    min_epochs: 1 # prevents early stopping
    max_epochs: 1000
    accelerator: gpu
    log_every_n_steps: 1
    deterministic: False
    # strategy: ddp_find_unused_parameters_true
    strategy: ddp
    check_val_every_n_epoch: 4
    accumulate_grad_batches: 2
  checkpointer:
    dirpath: ckpt/${experiment.wandb.project}/${experiment.wandb.name}
    save_last: True
    save_top_k: 3
  # Keep this null. Will be populated at runtime.
  inference_dir: null
  lawa:
    use_lawa: false
    lawa_start_epoch: 10
    lawa_k: 6
    lawa_use_ema: false
    lawa_decay_rate: 0.9

pmpnn_dir: ./ProteinMPNN
folding:
  seq_per_sample: 8
  folding_model: esmf # esmf or af2
  own_device: False
  pmpnn_path: ./ProteinMPNN/
  pt_hub_dir: ./../.cache/torch/
  colabfold_path: path/to/colabfold-conda/bin/colabfold_batch # for AF2
  self_consistency_metric : scRMSD # scRMSD or scTM
  use_pae: true
  calculate_novelty: false